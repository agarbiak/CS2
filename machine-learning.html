<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 16 Machine learning | Risk Modelling and Survival Analysis</title>
  <meta name="description" content="Risk modelling and survival analysis for actuaries providing R code examples." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 16 Machine learning | Risk Modelling and Survival Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Risk modelling and survival analysis for actuaries providing R code examples." />
  <meta name="github-repo" content="agarbiak/CS2" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 16 Machine learning | Risk Modelling and Survival Analysis" />
  
  <meta name="twitter:description" content="Risk modelling and survival analysis for actuaries providing R code examples." />
  

<meta name="author" content="Alex Garbiak" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />
<link rel="prev" href="mortality-projection.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Risk Modelling and Survival Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#id-00-motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="id-01-setup.html"><a href="id-01-setup.html"><i class="fa fa-check"></i><b>2</b> R Setup</a><ul>
<li class="chapter" data-level="2.1" data-path="id-01-setup.html"><a href="id-01-setup.html#id-01-environment"><i class="fa fa-check"></i><b>2.1</b> Preparing your environment</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="loss-distributions.html"><a href="loss-distributions.html"><i class="fa fa-check"></i><b>3</b> Loss distributions</a><ul>
<li class="chapter" data-level="3.1" data-path="loss-distributions.html"><a href="loss-distributions.html#id-02-learning-objectives"><i class="fa fa-check"></i><b>3.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="loss-distributions.html"><a href="loss-distributions.html#id-02-theory"><i class="fa fa-check"></i><b>3.2</b> Theory</a><ul>
<li class="chapter" data-level="3.2.1" data-path="loss-distributions.html"><a href="loss-distributions.html#probability-distributions-for-modelling-insurance-losses"><i class="fa fa-check"></i><b>3.2.1</b> Probability distributions for modelling insurance losses</a></li>
<li class="chapter" data-level="3.2.2" data-path="loss-distributions.html"><a href="loss-distributions.html#mechanisms-for-limiting-insurance-losses"><i class="fa fa-check"></i><b>3.2.2</b> Mechanisms for limiting insurance losses</a></li>
<li class="chapter" data-level="3.2.3" data-path="loss-distributions.html"><a href="loss-distributions.html#proportional-and-excess-of-loss-reinsurance"><i class="fa fa-check"></i><b>3.2.3</b> Proportional and Excess of Loss reinsurance</a></li>
<li class="chapter" data-level="3.2.4" data-path="loss-distributions.html"><a href="loss-distributions.html#estimating-parameters-of-loss-distributions-with-complete-data"><i class="fa fa-check"></i><b>3.2.4</b> Estimating parameters of loss distributions with complete data</a></li>
<li class="chapter" data-level="3.2.5" data-path="loss-distributions.html"><a href="loss-distributions.html#estimating-parameters-of-loss-distributions-with-incomplete-data"><i class="fa fa-check"></i><b>3.2.5</b> Estimating parameters of loss distributions with incomplete data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="loss-distributions.html"><a href="loss-distributions.html#id-02-practice"><i class="fa fa-check"></i><b>3.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="compound-distributions.html"><a href="compound-distributions.html"><i class="fa fa-check"></i><b>4</b> Compound loss distributions</a><ul>
<li class="chapter" data-level="4.1" data-path="compound-distributions.html"><a href="compound-distributions.html#id-03-learning-objectives"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="compound-distributions.html"><a href="compound-distributions.html#id-03-theory"><i class="fa fa-check"></i><b>4.2</b> Theory</a><ul>
<li class="chapter" data-level="4.2.1" data-path="compound-distributions.html"><a href="compound-distributions.html#modelling-frequency-of-insurance-claims"><i class="fa fa-check"></i><b>4.2.1</b> Modelling frequency of insurance claims</a></li>
<li class="chapter" data-level="4.2.2" data-path="compound-distributions.html"><a href="compound-distributions.html#modelling-severity-of-insurance-claims"><i class="fa fa-check"></i><b>4.2.2</b> Modelling severity of insurance claims</a></li>
<li class="chapter" data-level="4.2.3" data-path="compound-distributions.html"><a href="compound-distributions.html#compound-loss-distributions"><i class="fa fa-check"></i><b>4.2.3</b> Compound loss distributions</a></li>
<li class="chapter" data-level="4.2.4" data-path="compound-distributions.html"><a href="compound-distributions.html#compound-loss-distributions-after-reinsurance"><i class="fa fa-check"></i><b>4.2.4</b> Compound loss distributions after reinsurance</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="compound-distributions.html"><a href="compound-distributions.html#id-03-practice"><i class="fa fa-check"></i><b>4.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="copulas.html"><a href="copulas.html"><i class="fa fa-check"></i><b>5</b> Copulas</a><ul>
<li class="chapter" data-level="5.1" data-path="copulas.html"><a href="copulas.html#id-04-learning-objectives"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="copulas.html"><a href="copulas.html#id-04-theory"><i class="fa fa-check"></i><b>5.2</b> Theory</a><ul>
<li class="chapter" data-level="5.2.1" data-path="copulas.html"><a href="copulas.html#characteristics-of-a-copula"><i class="fa fa-check"></i><b>5.2.1</b> Characteristics of a copula</a></li>
<li class="chapter" data-level="5.2.2" data-path="copulas.html"><a href="copulas.html#gaussian-copula"><i class="fa fa-check"></i><b>5.2.2</b> Gaussian copula</a></li>
<li class="chapter" data-level="5.2.3" data-path="copulas.html"><a href="copulas.html#archimedan-family-of-copulas"><i class="fa fa-check"></i><b>5.2.3</b> Archimedan family of copulas</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="copulas.html"><a href="copulas.html#id-04-practice"><i class="fa fa-check"></i><b>5.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="evt.html"><a href="evt.html"><i class="fa fa-check"></i><b>6</b> Extreme value theory</a><ul>
<li class="chapter" data-level="6.1" data-path="evt.html"><a href="evt.html#id-05-learning-objectives"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="evt.html"><a href="evt.html#id-05-theory"><i class="fa fa-check"></i><b>6.2</b> Theory</a><ul>
<li class="chapter" data-level="6.2.1" data-path="evt.html"><a href="evt.html#extreme-value-distributions"><i class="fa fa-check"></i><b>6.2.1</b> Extreme value distributions</a></li>
<li class="chapter" data-level="6.2.2" data-path="evt.html"><a href="evt.html#calcuating-and-interpreting-tail-weights"><i class="fa fa-check"></i><b>6.2.2</b> Calcuating and interpreting tail weights</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="evt.html"><a href="evt.html#id-05-practice"><i class="fa fa-check"></i><b>6.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="time-series.html"><a href="time-series.html"><i class="fa fa-check"></i><b>7</b> Time series</a><ul>
<li class="chapter" data-level="7.1" data-path="time-series.html"><a href="time-series.html#id-06-learning-objectives"><i class="fa fa-check"></i><b>7.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="time-series.html"><a href="time-series.html#id-06-theory"><i class="fa fa-check"></i><b>7.2</b> Theory</a><ul>
<li class="chapter" data-level="7.2.1" data-path="time-series.html"><a href="time-series.html#concept-and-properties-of-time-series"><i class="fa fa-check"></i><b>7.2.1</b> Concept and properties of time series</a></li>
<li class="chapter" data-level="7.2.2" data-path="time-series.html"><a href="time-series.html#concept-of-stationary-random-series"><i class="fa fa-check"></i><b>7.2.2</b> Concept of stationary random series</a></li>
<li class="chapter" data-level="7.2.3" data-path="time-series.html"><a href="time-series.html#concept-of-a-filter-applied-to-a-stationary-random-series"><i class="fa fa-check"></i><b>7.2.3</b> Concept of a filter applied to a stationary random series</a></li>
<li class="chapter" data-level="7.2.4" data-path="time-series.html"><a href="time-series.html#notation-for-operators"><i class="fa fa-check"></i><b>7.2.4</b> Notation for operators</a></li>
<li class="chapter" data-level="7.2.5" data-path="time-series.html"><a href="time-series.html#the-characteristic-equation-of-time-series"><i class="fa fa-check"></i><b>7.2.5</b> The characteristic equation of time series</a></li>
<li class="chapter" data-level="7.2.6" data-path="time-series.html"><a href="time-series.html#concept-and-properties-of-random-walks"><i class="fa fa-check"></i><b>7.2.6</b> Concept and properties of random walks</a></li>
<li class="chapter" data-level="7.2.7" data-path="time-series.html"><a href="time-series.html#concept-of-a-multivariate-autoregressive-model"><i class="fa fa-check"></i><b>7.2.7</b> Concept of a multivariate autoregressive model</a></li>
<li class="chapter" data-level="7.2.8" data-path="time-series.html"><a href="time-series.html#concept-of-cointegrated-time-series"><i class="fa fa-check"></i><b>7.2.8</b> Concept of cointegrated time series</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="time-series.html"><a href="time-series.html#id-06-practice"><i class="fa fa-check"></i><b>7.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>8</b> Stochastic processes</a><ul>
<li class="chapter" data-level="8.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#id-07-learning-objectives"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#id-07-theory"><i class="fa fa-check"></i><b>8.2</b> Theory</a><ul>
<li class="chapter" data-level="8.2.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#defining-stochastic-process"><i class="fa fa-check"></i><b>8.2.1</b> Defining stochastic process</a></li>
<li class="chapter" data-level="8.2.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#classifying-stochastic-processes"><i class="fa fa-check"></i><b>8.2.2</b> Classifying stochastic processes</a></li>
<li class="chapter" data-level="8.2.3" data-path="stochastic-processes.html"><a href="stochastic-processes.html#applications-of-mixed-processes"><i class="fa fa-check"></i><b>8.2.3</b> Applications of mixed processes</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="stochastic-processes.html"><a href="stochastic-processes.html#id-07-practice"><i class="fa fa-check"></i><b>8.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>9</b> Markov chains</a><ul>
<li class="chapter" data-level="9.1" data-path="markov-chains.html"><a href="markov-chains.html#id-08-learning-objectives"><i class="fa fa-check"></i><b>9.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="9.2" data-path="markov-chains.html"><a href="markov-chains.html#id-08-theory"><i class="fa fa-check"></i><b>9.2</b> Theory</a><ul>
<li class="chapter" data-level="9.2.1" data-path="markov-chains.html"><a href="markov-chains.html#features-of-a-markov-chain-model"><i class="fa fa-check"></i><b>9.2.1</b> Features of a Markov chain model</a></li>
<li class="chapter" data-level="9.2.2" data-path="markov-chains.html"><a href="markov-chains.html#chapman-kolmogorov-equations"><i class="fa fa-check"></i><b>9.2.2</b> Chapman-Kolmogorov equations</a></li>
<li class="chapter" data-level="9.2.3" data-path="markov-chains.html"><a href="markov-chains.html#stationary-distribution-for-a-markov-chain"><i class="fa fa-check"></i><b>9.2.3</b> Stationary distribution for a Markov chain</a></li>
<li class="chapter" data-level="9.2.4" data-path="markov-chains.html"><a href="markov-chains.html#frequency-based-experience-rating"><i class="fa fa-check"></i><b>9.2.4</b> Frequency based experience rating</a></li>
<li class="chapter" data-level="9.2.5" data-path="markov-chains.html"><a href="markov-chains.html#time-inhomogeneous-markov-chain-model"><i class="fa fa-check"></i><b>9.2.5</b> Time-inhomogeneous Markov chain model</a></li>
<li class="chapter" data-level="9.2.6" data-path="markov-chains.html"><a href="markov-chains.html#markov-chains-in-modelling"><i class="fa fa-check"></i><b>9.2.6</b> Markov chains in modelling</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="markov-chains.html"><a href="markov-chains.html#id-08-practice"><i class="fa fa-check"></i><b>9.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="markov-processes.html"><a href="markov-processes.html"><i class="fa fa-check"></i><b>10</b> Markov processes</a><ul>
<li class="chapter" data-level="10.1" data-path="markov-processes.html"><a href="markov-processes.html#id-09-learning-objectives"><i class="fa fa-check"></i><b>10.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="markov-processes.html"><a href="markov-processes.html#id-09-theory"><i class="fa fa-check"></i><b>10.2</b> Theory</a><ul>
<li class="chapter" data-level="10.2.1" data-path="markov-processes.html"><a href="markov-processes.html#features-of-a-markov-process-model"><i class="fa fa-check"></i><b>10.2.1</b> Features of a Markov process model</a></li>
<li class="chapter" data-level="10.2.2" data-path="markov-processes.html"><a href="markov-processes.html#poisson-process"><i class="fa fa-check"></i><b>10.2.2</b> Poisson process</a></li>
<li class="chapter" data-level="10.2.3" data-path="markov-processes.html"><a href="markov-processes.html#kolmogorov-equations-for-a-markov-process"><i class="fa fa-check"></i><b>10.2.3</b> Kolmogorov equations for a Markov process</a></li>
<li class="chapter" data-level="10.2.4" data-path="markov-processes.html"><a href="markov-processes.html#solving-kolmogorv-equations"><i class="fa fa-check"></i><b>10.2.4</b> Solving Kolmogorv equations</a></li>
<li class="chapter" data-level="10.2.5" data-path="markov-processes.html"><a href="markov-processes.html#sickness-and-marriage-models"><i class="fa fa-check"></i><b>10.2.5</b> Sickness and marriage models</a></li>
<li class="chapter" data-level="10.2.6" data-path="markov-processes.html"><a href="markov-processes.html#markov-jump-process"><i class="fa fa-check"></i><b>10.2.6</b> Markov jump process</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="markov-processes.html"><a href="markov-processes.html#id-09-practice"><i class="fa fa-check"></i><b>10.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="survival-models.html"><a href="survival-models.html"><i class="fa fa-check"></i><b>11</b> Survival models</a></li>
<li class="chapter" data-level="12" data-path="lifetime-distributions.html"><a href="lifetime-distributions.html"><i class="fa fa-check"></i><b>12</b> Lifetime distributions</a></li>
<li class="chapter" data-level="13" data-path="transition-intensities.html"><a href="transition-intensities.html"><i class="fa fa-check"></i><b>13</b> Estimating transition intensities</a></li>
<li class="chapter" data-level="14" data-path="graduation.html"><a href="graduation.html"><i class="fa fa-check"></i><b>14</b> Graduation</a></li>
<li class="chapter" data-level="15" data-path="mortality-projection.html"><a href="mortality-projection.html"><i class="fa fa-check"></i><b>15</b> Mortality projection</a></li>
<li class="chapter" data-level="16" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>16</b> Machine learning</a><ul>
<li class="chapter" data-level="16.1" data-path="machine-learning.html"><a href="machine-learning.html#id-15-learning-objectives"><i class="fa fa-check"></i><b>16.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="16.2" data-path="machine-learning.html"><a href="machine-learning.html#id-15-theory"><i class="fa fa-check"></i><b>16.2</b> Theory</a><ul>
<li class="chapter" data-level="16.2.1" data-path="machine-learning.html"><a href="machine-learning.html#machine-learning-topics"><i class="fa fa-check"></i><b>16.2.1</b> Machine learning topics</a></li>
<li class="chapter" data-level="16.2.2" data-path="machine-learning.html"><a href="machine-learning.html#machine-learning-from-data"><i class="fa fa-check"></i><b>16.2.2</b> Machine learning from data</a></li>
<li class="chapter" data-level="16.2.3" data-path="machine-learning.html"><a href="machine-learning.html#supervised-machine-learning"><i class="fa fa-check"></i><b>16.2.3</b> Supervised machine learning</a></li>
<li class="chapter" data-level="16.2.4" data-path="machine-learning.html"><a href="machine-learning.html#unsupervised-machine-learning"><i class="fa fa-check"></i><b>16.2.4</b> Unsupervised machine learning</a></li>
<li class="chapter" data-level="16.2.5" data-path="machine-learning.html"><a href="machine-learning.html#penalised-regression"><i class="fa fa-check"></i><b>16.2.5</b> Penalised regression</a></li>
<li class="chapter" data-level="16.2.6" data-path="machine-learning.html"><a href="machine-learning.html#decision-trees"><i class="fa fa-check"></i><b>16.2.6</b> Decision trees</a></li>
<li class="chapter" data-level="16.2.7" data-path="machine-learning.html"><a href="machine-learning.html#perspectives-of-non-actuarial-professionals"><i class="fa fa-check"></i><b>16.2.7</b> Perspectives of non-actuarial professionals</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="machine-learning.html"><a href="machine-learning.html#id-15-practice"><i class="fa fa-check"></i><b>16.3</b> <code>R</code> Practice</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/agarbiak" target="blank">A book by Alex Garbiak</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Risk Modelling and Survival Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning" class="section level1">
<h1><span class="header-section-number">Chapter 16</span> Machine learning</h1>
<div id="id-15-learning-objectives" class="section level2">
<h2><span class="header-section-number">16.1</span> Learning Objectives</h2>
<ol style="list-style-type: decimal">
<li>Explain the main branches of machine learning and describe examples of the types of problems typically addressed by machine learning.</li>
<li>Explain and apply high-level concepts relevant to learning from data.</li>
<li>Describe and give examples of key supervised and unsupervised machine learning techniques, explaining the difference between regression and classification and between generative and discriminative models.</li>
<li>Explain in detail and use appropriate software to apply machine learning techniques (e.g. penalised regression and decision trees) to simple problems.</li>
<li>Demonstrate an understanding of the perspectives of statisticians, data scientists, and other quantitative researchers from non-actuarial backgrounds.</li>
</ol>
</div>
<div id="id-15-theory" class="section level2">
<h2><span class="header-section-number">16.2</span> Theory</h2>
<p><strong>TO ADD THEORY ABOUT MACHINE LEARNING HERE</strong></p>
<div id="machine-learning-topics" class="section level3">
<h3><span class="header-section-number">16.2.1</span> Machine learning topics</h3>
</div>
<div id="machine-learning-from-data" class="section level3">
<h3><span class="header-section-number">16.2.2</span> Machine learning from data</h3>
</div>
<div id="supervised-machine-learning" class="section level3">
<h3><span class="header-section-number">16.2.3</span> Supervised machine learning</h3>
</div>
<div id="unsupervised-machine-learning" class="section level3">
<h3><span class="header-section-number">16.2.4</span> Unsupervised machine learning</h3>
</div>
<div id="penalised-regression" class="section level3">
<h3><span class="header-section-number">16.2.5</span> Penalised regression</h3>
</div>
<div id="decision-trees" class="section level3">
<h3><span class="header-section-number">16.2.6</span> Decision trees</h3>
</div>
<div id="perspectives-of-non-actuarial-professionals" class="section level3">
<h3><span class="header-section-number">16.2.7</span> Perspectives of non-actuarial professionals</h3>
</div>
</div>
<div id="id-15-practice" class="section level2">
<h2><span class="header-section-number">16.3</span> <code>R</code> Practice</h2>
<p>We are managing a <code>portfolio</code> of investments that contains 200 assets. In this <code>portfolio</code> we measure the following features:</p>
<ul>
<li>Price-to-Earnings Ratio (“<em>PE</em>”), labelled <span class="math inline">\(x1\)</span> with <span class="math inline">\(x1 \sim \mathcal{N}(3,\,1)\)</span></li>
<li>Price-to-Book Ratio (“<em>PB</em>”), labelled <span class="math inline">\(x2\)</span> with 65% of the assets following <span class="math inline">\(\mathcal{N}(10,\,1)\)</span> and the remaining 35% following <span class="math inline">\(\mathcal{N}(4,\,1)\)</span></li>
</ul>
<p>We replicate this in <code>R</code> as follows:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="machine-learning.html#cb11-1"></a><span class="kw">library</span>(dplyr) <span class="co"># Data manipulation</span></span>
<span id="cb11-2"><a href="machine-learning.html#cb11-2"></a></span>
<span id="cb11-3"><a href="machine-learning.html#cb11-3"></a><span class="kw">set.seed</span>(<span class="dv">42</span>) <span class="co"># Fix result</span></span>
<span id="cb11-4"><a href="machine-learning.html#cb11-4"></a>portfolio &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb11-5"><a href="machine-learning.html#cb11-5"></a>  <span class="dt">x1 =</span> <span class="kw">rnorm</span>(<span class="dv">200</span>, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb11-6"><a href="machine-learning.html#cb11-6"></a>  <span class="dt">x2 =</span> <span class="kw">scale</span>(</span>
<span id="cb11-7"><a href="machine-learning.html#cb11-7"></a>    <span class="kw">c</span>(</span>
<span id="cb11-8"><a href="machine-learning.html#cb11-8"></a>      <span class="kw">rnorm</span>(<span class="dv">70</span>, <span class="dv">4</span>, <span class="dv">1</span>),</span>
<span id="cb11-9"><a href="machine-learning.html#cb11-9"></a>      <span class="kw">rnorm</span>(<span class="dv">130</span>, <span class="dv">10</span>, <span class="dv">1</span>)</span>
<span id="cb11-10"><a href="machine-learning.html#cb11-10"></a>    )</span>
<span id="cb11-11"><a href="machine-learning.html#cb11-11"></a>  )</span>
<span id="cb11-12"><a href="machine-learning.html#cb11-12"></a>)</span>
<span id="cb11-13"><a href="machine-learning.html#cb11-13"></a></span>
<span id="cb11-14"><a href="machine-learning.html#cb11-14"></a><span class="kw">glimpse</span>(portfolio)</span></code></pre></div>
<pre><code>## Rows: 200
## Columns: 2
## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.4042683, 2.8938755...
## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, -1.7225948, -1.6...</code></pre>
<p>Here the <code class="sourceCode r"><span class="kw">scale</span>()</code> function scales each element in the result by subtracting the sample mean and dividing by the sample standard deviation.</p>
<p>Next we want to explore whether these 200 assets can be divided into two clusters which we will label arbitrarily <code>A</code> and <code>B</code> based on the two metrics we have measured, PE (as <span class="math inline">\(x1\)</span>) and PB (as <span class="math inline">\(x2\)</span>).</p>
<p>We will first assign the assets evenly into these two clusters:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="machine-learning.html#cb13-1"></a>group_label_stage1 &lt;-<span class="st"> </span><span class="kw">c</span>(</span>
<span id="cb13-2"><a href="machine-learning.html#cb13-2"></a>  <span class="kw">rep</span>(<span class="st">&quot;A&quot;</span>, <span class="dv">100</span>),</span>
<span id="cb13-3"><a href="machine-learning.html#cb13-3"></a>  <span class="kw">rep</span>(<span class="st">&quot;B&quot;</span>, <span class="dv">100</span>)</span>
<span id="cb13-4"><a href="machine-learning.html#cb13-4"></a>)</span>
<span id="cb13-5"><a href="machine-learning.html#cb13-5"></a></span>
<span id="cb13-6"><a href="machine-learning.html#cb13-6"></a>portfolio &lt;-<span class="st"> </span>portfolio <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb13-7"><a href="machine-learning.html#cb13-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">group_label_stage1 =</span> group_label_stage1)</span>
<span id="cb13-8"><a href="machine-learning.html#cb13-8"></a></span>
<span id="cb13-9"><a href="machine-learning.html#cb13-9"></a>ClusterACentre &lt;-<span class="st"> </span><span class="kw">c</span>(</span>
<span id="cb13-10"><a href="machine-learning.html#cb13-10"></a>  <span class="kw">mean</span>(portfolio<span class="op">$</span>x1[portfolio<span class="op">$</span>group_label_stage1 <span class="op">==</span><span class="st"> &quot;A&quot;</span>]),</span>
<span id="cb13-11"><a href="machine-learning.html#cb13-11"></a>  <span class="kw">mean</span>(portfolio<span class="op">$</span>x2[portfolio<span class="op">$</span>group_label_stage1 <span class="op">==</span><span class="st"> &quot;A&quot;</span>])</span>
<span id="cb13-12"><a href="machine-learning.html#cb13-12"></a>)</span>
<span id="cb13-13"><a href="machine-learning.html#cb13-13"></a></span>
<span id="cb13-14"><a href="machine-learning.html#cb13-14"></a>ClusterBCentre &lt;-<span class="st"> </span><span class="kw">c</span>(</span>
<span id="cb13-15"><a href="machine-learning.html#cb13-15"></a>  <span class="kw">mean</span>(portfolio<span class="op">$</span>x1[portfolio<span class="op">$</span>group_label_stage1 <span class="op">==</span><span class="st"> &quot;B&quot;</span>]),</span>
<span id="cb13-16"><a href="machine-learning.html#cb13-16"></a>  <span class="kw">mean</span>(portfolio<span class="op">$</span>x2[portfolio<span class="op">$</span>group_label_stage1 <span class="op">==</span><span class="st"> &quot;B&quot;</span>])</span>
<span id="cb13-17"><a href="machine-learning.html#cb13-17"></a>)</span>
<span id="cb13-18"><a href="machine-learning.html#cb13-18"></a></span>
<span id="cb13-19"><a href="machine-learning.html#cb13-19"></a><span class="kw">glimpse</span>(portfolio)</span></code></pre></div>
<pre><code>## Rows: 200
## Columns: 3
## $ x1                 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40...
## $ x2                 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ...
## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;...</code></pre>
<p>We have:</p>
<ul>
<li>The centre of cluster <code>A</code>, given by <span class="math inline">\((x1_A,\, x2_A)\)</span> is 3.033, -0.691, and</li>
<li>The centre of cluster <code>B</code>, given by <span class="math inline">\((x1_A,\, x2_A)\)</span> is 2.913, 0.691.</li>
</ul>
<p>Next we want to calculate the Euclidean distance between:</p>
<ul>
<li><span class="math inline">\((x1, x2)\)</span> and the centre of cluster <code>A</code>, and</li>
<li><span class="math inline">\((x1, x2)\)</span> and the centre of cluster <code>B</code>.</li>
</ul>
<p>We will label these distances as <code>dist_A</code> and <code>dist_B</code> respectively.</p>
<p>The Euclidean distance is defined as:</p>
<ul>
<li>For <code>dist_A</code>: <span class="math inline">\(\sqrt{(x1-x1_A)^2+(x2-x2_A)^2}\)</span>, and</li>
<li>For <code>dist_B</code>: <span class="math inline">\(\sqrt{(x1-x1_B)^2+(x2-x2_B)^2}\)</span>.</li>
</ul>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="machine-learning.html#cb15-1"></a>dist_A &lt;-<span class="st"> </span><span class="kw">sqrt</span>(</span>
<span id="cb15-2"><a href="machine-learning.html#cb15-2"></a>  (portfolio<span class="op">$</span>x1 <span class="op">-</span><span class="st"> </span>ClusterACentre[<span class="dv">1</span>])<span class="op">^</span><span class="dv">2</span> </span>
<span id="cb15-3"><a href="machine-learning.html#cb15-3"></a>  <span class="op">+</span><span class="st"> </span>(portfolio<span class="op">$</span>x2 <span class="op">-</span><span class="st"> </span>ClusterACentre[<span class="dv">2</span>])<span class="op">^</span><span class="dv">2</span> </span>
<span id="cb15-4"><a href="machine-learning.html#cb15-4"></a>)</span>
<span id="cb15-5"><a href="machine-learning.html#cb15-5"></a></span>
<span id="cb15-6"><a href="machine-learning.html#cb15-6"></a>dist_B &lt;-<span class="st"> </span><span class="kw">sqrt</span>(</span>
<span id="cb15-7"><a href="machine-learning.html#cb15-7"></a>  (portfolio<span class="op">$</span>x1 <span class="op">-</span><span class="st"> </span>ClusterBCentre[<span class="dv">1</span>])<span class="op">^</span><span class="dv">2</span> </span>
<span id="cb15-8"><a href="machine-learning.html#cb15-8"></a>  <span class="op">+</span><span class="st"> </span>(portfolio<span class="op">$</span>x2 <span class="op">-</span><span class="st"> </span>ClusterBCentre[<span class="dv">2</span>])<span class="op">^</span><span class="dv">2</span> </span>
<span id="cb15-9"><a href="machine-learning.html#cb15-9"></a>)</span>
<span id="cb15-10"><a href="machine-learning.html#cb15-10"></a></span>
<span id="cb15-11"><a href="machine-learning.html#cb15-11"></a>portfolio &lt;-<span class="st"> </span>portfolio <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-12"><a href="machine-learning.html#cb15-12"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb15-13"><a href="machine-learning.html#cb15-13"></a>    <span class="dt">dist_A =</span> dist_A,</span>
<span id="cb15-14"><a href="machine-learning.html#cb15-14"></a>    <span class="dt">dist_B =</span> dist_B</span>
<span id="cb15-15"><a href="machine-learning.html#cb15-15"></a>  )</span>
<span id="cb15-16"><a href="machine-learning.html#cb15-16"></a></span>
<span id="cb15-17"><a href="machine-learning.html#cb15-17"></a><span class="kw">glimpse</span>(portfolio)</span></code></pre></div>
<pre><code>## Rows: 200
## Columns: 5
## $ x1                 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40...
## $ x2                 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ...
## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;...
## $ dist_A             &lt;dbl&gt; 1.8210075, 0.7626050, 0.3871328, 0.6067517, 1.09...
## $ dist_B             &lt;dbl&gt; 2.995957, 1.916835, 1.646514, 1.481271, 2.463299...</code></pre>
<p>Now we will update the cluster labels (<code>A</code> and <code>B</code>) by assigning to each asset the label of the cluster whose centre is nearest from <code>dist_A</code> and <code>dist_B</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="machine-learning.html#cb17-1"></a>portfolio &lt;-<span class="st"> </span>portfolio <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb17-2"><a href="machine-learning.html#cb17-2"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb17-3"><a href="machine-learning.html#cb17-3"></a>    <span class="dt">group_label_stage2 =</span> <span class="kw">ifelse</span>(portfolio<span class="op">$</span>dist_A <span class="op">&lt;=</span><span class="st"> </span>portfolio<span class="op">$</span>dist_B, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>)</span>
<span id="cb17-4"><a href="machine-learning.html#cb17-4"></a>  )</span>
<span id="cb17-5"><a href="machine-learning.html#cb17-5"></a></span>
<span id="cb17-6"><a href="machine-learning.html#cb17-6"></a><span class="kw">glimpse</span>(portfolio)</span></code></pre></div>
<pre><code>## Rows: 200
## Columns: 6
## $ x1                 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40...
## $ x2                 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ...
## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;...
## $ dist_A             &lt;dbl&gt; 1.8210075, 0.7626050, 0.3871328, 0.6067517, 1.09...
## $ dist_B             &lt;dbl&gt; 2.995957, 1.916835, 1.646514, 1.481271, 2.463299...
## $ group_label_stage2 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;...</code></pre>
<p>Let’s generate a 2x2 matrix showing the number of assets with each possible combination of values from <code>group_label_stage1</code> and <code>group_label_stage2</code>:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="machine-learning.html#cb19-1"></a>combos &lt;-<span class="st"> </span>portfolio <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb19-2"><a href="machine-learning.html#cb19-2"></a><span class="st">  </span><span class="kw">count</span>(group_label_stage1, group_label_stage2)</span>
<span id="cb19-3"><a href="machine-learning.html#cb19-3"></a></span>
<span id="cb19-4"><a href="machine-learning.html#cb19-4"></a><span class="kw">matrix</span>(</span>
<span id="cb19-5"><a href="machine-learning.html#cb19-5"></a>  combos<span class="op">$</span>n,</span>
<span id="cb19-6"><a href="machine-learning.html#cb19-6"></a>  <span class="dt">nrow =</span> <span class="dv">2</span>,</span>
<span id="cb19-7"><a href="machine-learning.html#cb19-7"></a>  <span class="dt">dimnames =</span> <span class="kw">list</span>(</span>
<span id="cb19-8"><a href="machine-learning.html#cb19-8"></a>    <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>),</span>
<span id="cb19-9"><a href="machine-learning.html#cb19-9"></a>    <span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>)</span>
<span id="cb19-10"><a href="machine-learning.html#cb19-10"></a>  )</span>
<span id="cb19-11"><a href="machine-learning.html#cb19-11"></a>)</span></code></pre></div>
<pre><code>##    A  B
## A 71  1
## B 29 99</code></pre>
<p>Finally let’s plot <code>x1</code> and <code>x2</code> coloured using the latest clustering labelling:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="machine-learning.html#cb21-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb21-2"><a href="machine-learning.html#cb21-2"></a></span>
<span id="cb21-3"><a href="machine-learning.html#cb21-3"></a>portfolio <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb21-4"><a href="machine-learning.html#cb21-4"></a><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb21-5"><a href="machine-learning.html#cb21-5"></a><span class="st">  </span><span class="kw">geom_point</span>(</span>
<span id="cb21-6"><a href="machine-learning.html#cb21-6"></a>    <span class="kw">aes</span>(x1, x2, <span class="dt">colour =</span> group_label_stage2)</span>
<span id="cb21-7"><a href="machine-learning.html#cb21-7"></a>  )</span></code></pre></div>
<p><img src="book_files/figure-html/15-machine-learning-07-1.png" width="672" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mortality-projection.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["twitter", "linkedin"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/agarbiak/CS2/edit/main/15-machine-learning.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
