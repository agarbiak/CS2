[
["index.html", "Risk Modelling and Survival Analysis Introduction Motivation", " Risk Modelling and Survival Analysis Alex Garbiak 04 October, 2020 Introduction This book is unpublished and should be considered an early build version. There will be bugs, typos and errors. Please report them here. Motivation The purpose of this book is to help actuaries studying Risk Modelling and Survival Analysis (CS2) from the Institute and Faculty of Actuaries by providing R code examples across the following topic areas: Random variables and distributions for risk modelling Time series Stochastic processes Survival models Machine learning "],
["r-setup.html", "Chapter 1 R Setup 1.1 Preparing your environment 1.2 Basic interations with R", " Chapter 1 R Setup 1.1 Preparing your environment The Institute and Faculty of Actuaries have provided their own guide to getting up and running with R. The steps to have R working is dependant on your operating system. Thankfully the following resources should allow for your local installation of R to be relatively painless: Download and install R from CRAN1. Download and install an integrated development environment, I recommend RStudio Desktop. 1.2 Basic interations with R R prefers vectorised operations (over concepts like for loops) # This is the syntax for comments in R (1:10) + 2 # Notice how we add element-wise in R ## [1] 3 4 5 6 7 8 9 10 11 12 We assign values to variables using the &lt;- (“assignment”) operator2. x &lt;- 1:10 y &lt;- x + 2 x &lt;- x + x # Notice that we can re-assign values to variables z &lt;- x + 2 y ## [1] 3 4 5 6 7 8 9 10 11 12 z ## [1] 4 6 8 10 12 14 16 18 20 22 Even though \\(z\\) is assigned the same way as we assigned \\(y\\), note that \\(y \\neq z\\) so execution order matters in R We now add functions to the R code which has the form function_name(arguments = &quot;values&quot;, ...) # Combine function, used often to create vectors: x &lt;- c(1:3, 6:20, 21:42) # Another function with arguments: y &lt;- sample(x, size = 3) y ## [1] 39 28 37 Let’s create a matrix in R Note: Matrix multiplication requires the %*% syntax first_matrix &lt;- matrix(1:9, byrow = TRUE, nrow = 3) first_matrix %*% first_matrix ## [,1] [,2] [,3] ## [1,] 30 36 42 ## [2,] 66 81 96 ## [3,] 102 126 150 A data.frame is a very popular data structure used in R. Each input variable has to have the same length but can be of different types (strings, integers, booleans, etc.). # Input vectors for the data.frame name &lt;- c(&quot;Mercury&quot;, &quot;Venus&quot;, &quot;Earth&quot;, &quot;Mars&quot;, &quot;Jupiter&quot;, &quot;Saturn&quot;, &quot;Uranus&quot;, &quot;Neptune&quot;) surface_gravity &lt;- c(0.38, 0.904, 1, 0.3794, 2.528, 1.065, 0.886, 1.14) # Create a data.frame from the vectors solar_system &lt;- data.frame(name, surface_gravity) str(solar_system) ## &#39;data.frame&#39;: 8 obs. of 2 variables: ## $ name : chr &quot;Mercury&quot; &quot;Venus&quot; &quot;Earth&quot; &quot;Mars&quot; ... ## $ surface_gravity: num 0.38 0.904 1 0.379 2.528 ... R has built in logic expressions: Operator Description &lt; (&lt;=) less than (or equal to) &gt; (&gt;=) greater than (or equal to) == exactly equal to ! NOT &amp; AND (element-wise) | OR (element-wise) != not equal to We can use logical expressions to effectively filter data Here we subset the data using the [...] syntax x &lt;- 1:10 x[x != 5 &amp; x &lt; 7] ## [1] 1 2 3 4 6 We can select objects using the $ symbol - see ?Extract for more help here #data.frame[rows to select, columns to select] solar_system[solar_system$name == &quot;Jupiter&quot;, c(1:2)] ## name surface_gravity ## 5 Jupiter 2.528 We can extend R’s functionality by loading packages: # Load the ggplot2 package library(ggplot2) Did you get an error from R trying this? To load packages they need to be installed first: install.packages(&quot;ggplot2&quot;) CRAN is the The Comprehensive R Archive Network - read more on the CRAN website↩︎ We can also assign values using the more familiar = symbol. In general this is discouraged, listen to Hadley Wickham.↩︎ "],
["loss-distributions.html", "Chapter 2 Loss distributions Learning Objectives Theory 2.1 Probability distributions for modelling insurance losses 2.2 Mechanisms for limiting insurance losses 2.3 Proportional and Excess of Loss reinsurance 2.4 Estimating parameters of loss distributions with complete data 2.5 Estimating parameters of loss distributions with incomplete data R Practice", " Chapter 2 Loss distributions Learning Objectives Describe the properties of the statistical distributions which are suitable for modelling individual and aggregate losses. Explain the concepts of excesses, deductibles and retention limits. Describe the operation of proportional and excess of loss reinsurance. Derive the distribution and corresponding moments of the claim amounts paid by the insurer and the reinsurer in the presence of excesses (deductibles) and reinsurance. Estimate the parameters of a failure time or loss distribution when the data is complete, or when it is incomplete, using maximum likelihood and the method of moments. Fit a statistical distribution to a dataset and calculate appropriate goodness of fit measures. Theory R was designed to be used for statistical computing - so it handles randomness well! set.seed(42) # Fixes result die_throws &lt;- sample(1:6, 10000, replace = TRUE) mean(die_throws) ## [1] 3.4627 2.1 Probability distributions for modelling insurance losses R has in-built functions for probability distributions: d&lt;distribution-name&gt; \\(:=\\) density (PDF), i.e. \\(f_X(x)\\) p&lt;distribution-name&gt; \\(:=\\) probability distribution cumulative function (CDF), i.e. \\(F_X(x) =\\boldsymbol{P}(X \\leq x)\\) q&lt;distribution-name&gt; \\(:=\\) quantile function, i.e. return \\(x\\) such that \\(\\boldsymbol{P}(X \\leq x) = p\\) r&lt;distribution-name&gt; \\(:=\\) random deviates, i.e. (psuedo) random number generator for a given distribution Where &lt;distribution-name&gt; \\(=\\) Normal, uniform, lognormal, Student’s t, Poisson, binormal, Weibull … see ?distributions() for more information R Code Definition rnorm(1) Generates \\(x_1\\) where \\(X \\sim \\mathcal{N}(0,\\,1)\\) rnorm(y, mean=10, sd=2) Generates \\(\\{y_1,\\,y_2,\\,\\dots\\}\\) with \\(Y \\sim \\mathcal{N}(10,\\,2^2)\\) runif(3, min=5, max=10) Generates \\(\\{z_1,\\,z_2,\\,z_3\\}\\) where \\(Z \\sim \\mathcal{U}(5,\\,10)\\) dbinom(4, size=5, prob=0.5) Computes \\(\\boldsymbol{P}(X = 4)\\) where \\(X \\sim \\mathcal{Bin}(5,\\,0.5)\\) pgamma(0.2, shape=2, rate=2)*See footnote Computes \\(F_Y(0.2)\\) where \\(Y \\sim \\mathcal{\\Gamma}(2,\\,2)\\), i.e. \\(\\boldsymbol{P}(Y\\leq 0.2)\\) qexp(0.5, rate = 2) Determines smallest value of \\(z\\) for \\(\\boldsymbol{P}(Z \\leq z) = 0.5\\) where \\(Z \\sim Exp(2)\\) 2.2 Mechanisms for limiting insurance losses 2.3 Proportional and Excess of Loss reinsurance 2.4 Estimating parameters of loss distributions with complete data 2.5 Estimating parameters of loss distributions with incomplete data R Practice We are investigating the reinsurance arrangement of 1,000 insurance claims named X with the following characteristics: \\(X \\sim Exp(0.01)\\) Unlimited excess of loss reinsurance, with a retention level of \\(M = 400\\) library(dplyr) # Data manipulation set.seed(42) # Fix result X &lt;- rexp( n = 1000, rate = 0.01 ) M &lt;- 400 summary(X) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0281 33.4354 75.5324 107.7943 145.8514 846.2336 We want to determine the proportion of claims that are fully covered by the insurer: Proportion &lt;- sum(X &lt;= M) / length(X) The proportion of claims that are fully covered by the insurer is 97.8%. Next, for each claim, we want to calculate the net (of reinsurance) amount paid by the insurer. We will record this in a vector called Y: Y &lt;- ifelse(X &gt; M, M, X) summary(Y) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0281 33.4354 75.5324 105.0863 145.8514 400.0000 Likewise, for each claim, we want to calculate the amount paid by the reinsurer. We will record this in a vector called Z: Z &lt;- ifelse(X &gt; M, X - M, 0) summary(Z) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 0.000 0.000 2.708 0.000 446.234 Now let us assume that the underlying gross claims distribution follows an exponential distribution of some unknown rate \\(\\lambda\\). We will estimate \\(\\lambda\\) using only the retained claim amounts which we have recorded in vector Y. First let’s calculate the log-likelihood as a function of the parameter \\(\\lambda\\) and claims data Y: #TO DO We now determine the value of \\(\\lambda\\) at which the log-likelihood function reaches its maximum: #TO DO Finally let’s plot the results: library(ggplot2) #TO DO "],
["compound-loss-distributions.html", "Chapter 3 Compound loss distributions Learning Objectives Theory 3.1 Modelling frequency of insurance claims 3.2 Modelling severity of insurance claims 3.3 Compound loss distributions 3.4 Compound loss distributions after reinsurance R Practice", " Chapter 3 Compound loss distributions Learning Objectives Construct models appropriate for short term insurance contracts in terms of the numbers of claims and the amounts of individual claims. Describe the major simplifying assumptions underlying such models. Define a compound Poisson distribution and show that the sum of independent random variables each having a compound Poisson distribution also has a compound Poisson distribution. Derive the mean, variance and coefficient of skewness for compound binomial, compound Poisson and compound negative binomial random variables. Repeat this for both the insurer and the reinsurer after the operation of simple forms of proportional and excess of loss reinsurance. Theory TO ADD THEORY ABOUT COMPOUND MODELLING HERE 3.1 Modelling frequency of insurance claims 3.2 Modelling severity of insurance claims 3.3 Compound loss distributions 3.3.1 Compound binomial 3.3.2 Compound Poisson 3.3.3 Compound negative binomial 3.4 Compound loss distributions after reinsurance R Practice "],
["copulas.html", "Chapter 4 Copulas Learning Objectives Theory R Practice", " Chapter 4 Copulas Learning Objectives Describe how a copula can be characterised as a multivariate distribution function which is a function of the marginal distribution functions of its variates, and explain how this allows the marginal distributions to be investigated separately from the dependency between them. Explain the meaning of the terms dependence or concordance, upper and lower tail dependence; and state in general terms how tail dependence can be used to help select a copula suitable for modelling particular types of risk. Describe the form and characteristics of the Gaussian copula and the Archimedean family of copulas. Theory TO ADD THEORY ABOUT COPULAS HERE 4.0.1 Characteristics of a copula 4.0.2 Gaussian copula 4.0.3 Archimedan family of copulas R Practice "],
["extreme-value-theory.html", "Chapter 5 Extreme value theory Learning Objectives Theory 5.1 Extreme value distributions 5.2 Calcuating and interpreting tail weights R Practice", " Chapter 5 Extreme value theory Learning Objectives Recognise extreme value distributions, suitable for modelling the distribution of severity of loss and their relationships. Calculate various measures of tail weight and interpret the results to compare the tail weights. Theory TO ADD THEORY ABOUT EXTREME VALUE THEORY HERE 5.1 Extreme value distributions 5.2 Calcuating and interpreting tail weights R Practice "],
["time-series.html", "Chapter 6 Time series Learning Objectives 6.1 Theory 6.2 Concept and properties of time series 6.3 Concept of stationary random series 6.4 Concept of a filter applied to a stationary random series 6.5 Notation for operators 6.6 The characteristic equation of time series 6.7 Concept and properties of random walks 6.8 Concept of a multivariate autoregressive model 6.9 Concept of cointegrated time series R Practice", " Chapter 6 Time series Learning Objectives Explain the concept and general properties of stationary, \\(I(0)\\), and integrated, \\(I(1)\\), univariate time series. Explain the concept of a stationary random series. Explain the concept of a filter applied to a stationary random series. Know the notation for backwards shift operator, backwards difference operator, and the concept of roots of the characteristic equation of time series. Explain the concepts and basic properties of autoregressive (AR), moving average (MA), autoregressive moving average (ARMA) and autoregressive integrated moving average (ARIMA) time series. Explain the concept and properties of discrete random walks and random walks with normally distributed increments, both with and without drift. Explain the basic concept of a multivariate autoregressive model. Explain the concept of cointegrated time series. 6.1 Theory TO ADD THEORY ABOUT TIME SERIES HERE 6.2 Concept and properties of time series 6.3 Concept of stationary random series 6.4 Concept of a filter applied to a stationary random series 6.5 Notation for operators 6.6 The characteristic equation of time series 6.7 Concept and properties of random walks 6.8 Concept of a multivariate autoregressive model 6.9 Concept of cointegrated time series R Practice TO ADD R EXAMPLE ABOUT TIME SERIES HERE "],
["stochastic-processes.html", "Chapter 7 Stochastic processes Learning Objectives Theory 7.1 Defining stochastic process 7.2 Classifying stochastic processes 7.3 Applications of mixed processes R Practice", " Chapter 7 Stochastic processes Learning Objectives Define in general terms a stochastic process and in particular a counting process. Classify a stochastic process. Describe possible applications of mixed processes. Explain what is meant by the Markov property in the context of a stochastic process and in terms of filtrations. Theory TO ADD THEORY ABOUT STOCHASTIC PROCESSES HERE 7.1 Defining stochastic process 7.1.1 Defining a counting process 7.2 Classifying stochastic processes 7.2.1 Time basis Continous or discrete time 7.2.2 State space Continous or discrete state space 7.2.3 Mixed type stochastic process 7.3 Applications of mixed processes R Practice TO ADD R EXAMPLE ABOUT STOCHASTIC PROCESSES HERE "],
["markov-chains.html", "Chapter 8 Markov chains Learning Objectives Theory 8.1 Features of a Markov chain model 8.2 Chapman-Kolmogorov equations 8.3 Stationary distribution for a Markov chain 8.4 Frequency based experience rating 8.5 Time-inhomogeneous Markov chain model 8.6 Markov chains in modelling R Practice", " Chapter 8 Markov chains Learning Objectives State the essential features of a Markov chain model. State the Chapman-Kolmogorov equations that represent a Markov chain. Calculate the stationary distribution for a Markov chain in simple cases. Describe a system of frequency based experience rating in terms of a Markov chain and describe other simple applications. Describe a time-inhomogeneous Markov chain model and describe simple applications. Demonstrate how Markov chains can be used as a tool for modelling and how they can be simulated. Theory TO ADD THEORY ABOUT MARKOV CHAINS HERE 8.1 Features of a Markov chain model 8.2 Chapman-Kolmogorov equations 8.3 Stationary distribution for a Markov chain 8.4 Frequency based experience rating 8.5 Time-inhomogeneous Markov chain model 8.6 Markov chains in modelling 8.6.1 Simulating a Markov chain R Practice TO ADD R EXAMPLE ABOUT MARKOV CHAINS HERE "],
["markov-processes.html", "Chapter 9 Markov processes Learning Objectives Theory 9.1 Features of a Markov process model 9.2 Poisson process 9.3 Kolmogorov equations for a Markov process 9.4 Solving Kolmogorv equations 9.5 Sickness and marriage models 9.6 Markov jump process R Practice", " Chapter 9 Markov processes Learning Objectives State the essential features of a Markov process model. Define a Poisson process, derive the distribution of the number of events in a given time interval, derive the distribution of inter-event times, and apply these results. Derive the Kolmogorov equations for a Markov process with time independent and time/age dependent transition intensities. Solve the Kolmogorov equations in simple cases. State the Kolmogorov equations for a model where the transition intensities depend not only on age/time, but also on the duration of stay in one or more states. Describe sickness and marriage models in terms of duration dependent Markov processes and describe other simple applications. Demonstrate how Markov jump processes can be used as a tool for modelling and how they can be simulated. Theory TO ADD THEORY ABOUT MARKOV PROCESSES HERE 9.1 Features of a Markov process model 9.2 Poisson process 9.3 Kolmogorov equations for a Markov process 9.4 Solving Kolmogorv equations 9.4.1 Simple cases 9.4.2 More general cases 9.5 Sickness and marriage models 9.6 Markov jump process 9.6.1 Simulating a Markov jump process R Practice TO ADD R EXAMPLE ABOUT MARKOV PROCESSES HERE "],
["survival-models.html", "Chapter 10 Survival models", " Chapter 10 Survival models "],
["lifetime-distributions.html", "Chapter 11 Lifetime distributions", " Chapter 11 Lifetime distributions "],
["transition-intensities.html", "Chapter 12 Estimating transition intensities", " Chapter 12 Estimating transition intensities "],
["graduation.html", "Chapter 13 Graduation", " Chapter 13 Graduation "],
["mortality-projection.html", "Chapter 14 Mortality projection", " Chapter 14 Mortality projection "],
["machine-learning.html", "Chapter 15 Machine learning Learning Objectives Theory 15.1 Machine learning topics 15.2 Machine learning from data 15.3 Supervised machine learning 15.4 Unsupervised machine learning 15.5 Penalised regression 15.6 Decision trees 15.7 Perspectives of non-actuarial professionals R Practice", " Chapter 15 Machine learning Learning Objectives Explain the main branches of machine learning and describe examples of the types of problems typically addressed by machine learning. Explain and apply high-level concepts relevant to learning from data. Describe and give examples of key supervised and unsupervised machine learning techniques, explaining the difference between regression and classification and between generative and discriminative models. Explain in detail and use appropriate software to apply machine learning techniques (e.g. penalised regression and decision trees) to simple problems. Demonstrate an understanding of the perspectives of statisticians, data scientists, and other quantitative researchers from non-actuarial backgrounds. Theory TO ADD THEORY ABOUT MACHINE LEARNING HERE 15.1 Machine learning topics 15.2 Machine learning from data 15.3 Supervised machine learning 15.4 Unsupervised machine learning 15.5 Penalised regression 15.6 Decision trees 15.7 Perspectives of non-actuarial professionals R Practice We are managing a portfolio of investments that contains 200 assets. In this portfolio we measure the following features: Price-to-Earnings Ratio (“PE”), labelled \\(x1\\) with \\(x1 \\sim \\mathcal{N}(3,\\,1)\\) Price-to-Book Ratio (“PB”), labelled \\(x2\\) with 65% of the assets following \\(\\mathcal{N}(10,\\,1)\\) and the remaining 35% following \\(\\mathcal{N}(4,\\,1)\\) We replicate this in R as follows: library(dplyr) # Data manipulation set.seed(42) # Fix result portfolio &lt;- data.frame( x1 = rnorm(200, 3, 1), x2 = scale( c( rnorm(70, 4, 1), rnorm(130, 10, 1) ) ) ) glimpse(portfolio) ## Rows: 200 ## Columns: 2 ## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.4042683, 2.8938755... ## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, -1.7225948, -1.6... Here the scale() function scales each element in the result by subtracting the sample mean and dividing by the sample standard deviation. Next we want to explore whether these 200 assets can be divided into two clusters which we will label arbitrarily A and B based on the two metrics we have measured, PE (as \\(x1\\)) and PB (as \\(x2\\)). We will first assign the assets evenly into these two clusters: group_label_stage1 &lt;- c( rep(&quot;A&quot;, 100), rep(&quot;B&quot;, 100) ) portfolio &lt;- portfolio %&gt;% mutate(group_label_stage1 = group_label_stage1) ClusterACentre &lt;- c( mean(portfolio$x1[portfolio$group_label_stage1 == &quot;A&quot;]), mean(portfolio$x2[portfolio$group_label_stage1 == &quot;A&quot;]) ) ClusterBCentre &lt;- c( mean(portfolio$x1[portfolio$group_label_stage1 == &quot;B&quot;]), mean(portfolio$x2[portfolio$group_label_stage1 == &quot;B&quot;]) ) glimpse(portfolio) ## Rows: 200 ## Columns: 3 ## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40... ## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ... ## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... We have: The centre of cluster A, given by \\((x1_A,\\, x2_A)\\) is 3.033, -0.691, and The centre of cluster B, given by \\((x1_A,\\, x2_A)\\) is 2.913, 0.691. Next we want to calculate the Euclidean distance between: \\((x1, x2)\\) and the centre of cluster A, and \\((x1, x2)\\) and the centre of cluster B. We will label these distances as dist_A and dist_B respectively. The Euclidean distance is defined as: For dist_A: \\(\\sqrt{(x1-x1_A)^2+(x2-x2_A)^2}\\), and For dist_B: \\(\\sqrt{(x1-x1_B)^2+(x2-x2_B)^2}\\). dist_A &lt;- sqrt( (portfolio$x1 - ClusterACentre[1])^2 + (portfolio$x2 - ClusterACentre[2])^2 ) dist_B &lt;- sqrt( (portfolio$x1 - ClusterBCentre[1])^2 + (portfolio$x2 - ClusterBCentre[2])^2 ) portfolio &lt;- portfolio %&gt;% mutate( dist_A = dist_A, dist_B = dist_B ) glimpse(portfolio) ## Rows: 200 ## Columns: 5 ## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40... ## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ... ## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... ## $ dist_A &lt;dbl&gt; 1.8210075, 0.7626050, 0.3871328, 0.6067517, 1.09... ## $ dist_B &lt;dbl&gt; 2.995957, 1.916835, 1.646514, 1.481271, 2.463299... Now we will update the cluster labels (A and B) by assigning to each asset the label of the cluster whose centre is nearest from dist_A and dist_B. portfolio &lt;- portfolio %&gt;% mutate( group_label_stage2 = ifelse(portfolio$dist_A &lt;= portfolio$dist_B, &quot;A&quot;, &quot;B&quot;) ) glimpse(portfolio) ## Rows: 200 ## Columns: 6 ## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40... ## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ... ## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... ## $ dist_A &lt;dbl&gt; 1.8210075, 0.7626050, 0.3871328, 0.6067517, 1.09... ## $ dist_B &lt;dbl&gt; 2.995957, 1.916835, 1.646514, 1.481271, 2.463299... ## $ group_label_stage2 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... Let’s generate a 2x2 matrix showing the number of assets with each possible combination of values from group_label_stage1 and group_label_stage2: combos &lt;- portfolio %&gt;% count(group_label_stage1, group_label_stage2) matrix( combos$n, nrow = 2, dimnames = list( c(&quot;A&quot;, &quot;B&quot;), c(&quot;A&quot;, &quot;B&quot;) ) ) ## A B ## A 71 1 ## B 29 99 Finally let’s plot x1 and x2 coloured using the latest clustering labelling: library(ggplot2) portfolio %&gt;% ggplot() + geom_point( aes(x1, x2, colour = group_label_stage2) ) "]
]
