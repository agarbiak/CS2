[
["index.html", "Risk Modelling and Survival Analysis Chapter 1 Introduction 1.1 Motivation", " Risk Modelling and Survival Analysis Alex Garbiak 03 October, 2020 Chapter 1 Introduction This book is unpublished and should be considered an early build version. 1.1 Motivation The purpose of this book is to help actuaries studying Risk Modelling and Survival Analysis (CS2) from the Institute and Faculty of Actuaries by providing R code examples across the following topic areas: Random variables and distributions for risk modelling Time series Stochastic processes Survival models Machine learning "],
["setup.html", "Chapter 2 R Setup 2.1 Preparing your environment", " Chapter 2 R Setup 2.1 Preparing your environment The Institute and Faculty of Actuaries have provided their own guide to getting up and running with R. "],
["loss-distributions.html", "Chapter 3 Loss distributions 3.1 Learning Objectives 3.2 Theory 3.3 R Practice", " Chapter 3 Loss distributions 3.1 Learning Objectives Describe the properties of the statistical distributions which are suitable for modelling individual and aggregate losses. Explain the concepts of excesses, deductibles and retention limits. Describe the operation of proportional and excess of loss reinsurance. Derive the distribution and corresponding moments of the claim amounts paid by the insurer and the reinsurer in the presence of excesses (deductibles) and reinsurance. Estimate the parameters of a failure time or loss distribution when the data is complete, or when it is incomplete, using maximum likelihood and the method of moments. Fit a statistical distribution to a dataset and calculate appropriate goodness of fit measures. 3.2 Theory TO ADD THEORY ABOUT LOSS DISTRIBUTIONS HERE 3.2.1 Probability distributions for modelling insurance losses 3.2.2 Mechanisms for limiting insurance losses 3.2.3 Proportional and Excess of Loss reinsurance 3.2.4 Estimating parameters of loss distributions with complete data 3.2.5 Estimating parameters of loss distributions with incomplete data 3.3 R Practice We are investigating the reinsurance arrangement of 1,000 insurance claims named X with the following characteristics: \\(X \\sim Exp(0.01)\\) Unlimited excess of loss reinsurance, with a retention level of \\(M = 400\\) library(dplyr) # Data manipulation set.seed(1027) # Fix result X &lt;- rexp( n = 1000, rate = 0.01 ) M &lt;- 400 summary(X) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0711 29.1094 70.6747 97.8189 138.6831 738.9385 We want to determine the proportion of claims that are fully covered by the insurer: Proportion &lt;- sum(X &lt;= M) / length(X) The proportion of claims that are fully covered by the insurer is 98.7%. Next, for each claim, we want to calculate the net (of reinsurance) amount paid by the insurer. We will record this in a vector called Y: Y &lt;- ifelse(X &gt; M, M, X) summary(Y) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0711 29.1094 70.6747 96.4643 138.6831 400.0000 Likewise, for each claim, we want to calculate the amount paid by the reinsurer. We will record this in a vector called Z: Z &lt;- ifelse(X &gt; M, X - M, 0) summary(Z) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 0.000 0.000 1.355 0.000 338.938 Now let us assume that the underlying gross claims distribution follows an exponential distribution of some unknown rate \\(\\lambda\\). We will estimate \\(\\lambda\\) using only the retained claim amounts which we have recorded in vector Y. First let’s calculate the log-likelihood as a function of the parameter \\(\\lambda\\) and claims data Y: #TO DO We now determine the value of \\(\\lambda\\) at which the log-likelihood function reaches its maximum: #TO DO Finally let’s plot the results: library(ggplot2) #TO DO "],
["compound-distributions.html", "Chapter 4 Compound loss distributions 4.1 Learning Objectives 4.2 Theory 4.3 R Practice", " Chapter 4 Compound loss distributions 4.1 Learning Objectives Construct models appropriate for short term insurance contracts in terms of the numbers of claims and the amounts of individual claims. Describe the major simplifying assumptions underlying such models. Define a compound Poisson distribution and show that the sum of independent random variables each having a compound Poisson distribution also has a compound Poisson distribution. Derive the mean, variance and coefficient of skewness for compound binomial, compound Poisson and compound negative binomial random variables. Repeat this for both the insurer and the reinsurer after the operation of simple forms of proportional and excess of loss reinsurance. 4.2 Theory TO ADD THEORY ABOUT COMPOUND MODELLING HERE 4.2.1 Modelling frequency of insurance claims 4.2.2 Modelling severity of insurance claims 4.2.3 Compound loss distributions 4.2.3.1 Compound binomial 4.2.3.2 Compound Poisson 4.2.3.3 Compound negative binomial 4.2.4 Compound loss distributions after reinsurance 4.3 R Practice "],
["copulas.html", "Chapter 5 Copulas 5.1 Learning Objectives 5.2 Theory 5.3 R Practice", " Chapter 5 Copulas 5.1 Learning Objectives Describe how a copula can be characterised as a multivariate distribution function which is a function of the marginal distribution functions of its variates, and explain how this allows the marginal distributions to be investigated separately from the dependency between them. Explain the meaning of the terms dependence or concordance, upper and lower tail dependence; and state in general terms how tail dependence can be used to help select a copula suitable for modelling particular types of risk. Describe the form and characteristics of the Gaussian copula and the Archimedean family of copulas. 5.2 Theory TO ADD THEORY ABOUT COPULAS HERE 5.2.1 Characteristics of a copula 5.2.2 Gaussian copula 5.2.3 Archimedan family of copulas 5.3 R Practice "],
["evt.html", "Chapter 6 Extreme value theory 6.1 Learning Objectives 6.2 Theory 6.3 R Practice", " Chapter 6 Extreme value theory 6.1 Learning Objectives Recognise extreme value distributions, suitable for modelling the distribution of severity of loss and their relationships. Calculate various measures of tail weight and interpret the results to compare the tail weights. 6.2 Theory TO ADD THEORY ABOUT EXTREME VALUE THEORY HERE 6.2.1 Extreme value distributions 6.2.2 Calcuating and interpreting tail weights 6.3 R Practice "],
["time-series.html", "Chapter 7 Time series 7.1 Learning Objectives 7.2 Theory 7.3 R Practice", " Chapter 7 Time series 7.1 Learning Objectives Explain the concept and general properties of stationary, \\(I(0)\\), and integrated, \\(I(1)\\), univariate time series. Explain the concept of a stationary random series. Explain the concept of a filter applied to a stationary random series. Know the notation for backwards shift operator, backwards difference operator, and the concept of roots of the characteristic equation of time series. Explain the concepts and basic properties of autoregressive (AR), moving average (MA), autoregressive moving average (ARMA) and autoregressive integrated moving average (ARIMA) time series. Explain the concept and properties of discrete random walks and random walks with normally distributed increments, both with and without drift. Explain the basic concept of a multivariate autoregressive model. Explain the concept of cointegrated time series. 7.2 Theory TO ADD THEORY ABOUT TIME SERIES HERE 7.2.1 Concept and properties of time series 7.2.2 Concept of stationary random series 7.2.3 Concept of a filter applied to a stationary random series 7.2.4 Notation for operators 7.2.5 The characteristic equation of time series 7.2.6 Concept and properties of random walks 7.2.7 Concept of a multivariate autoregressive model 7.2.8 Concept of cointegrated time series 7.3 R Practice TO ADD R EXAMPLE ABOUT TIME SERIES HERE "],
["stochastic-processes.html", "Chapter 8 Stochastic processes 8.1 Learning Objectives 8.2 Theory 8.3 R Practice", " Chapter 8 Stochastic processes 8.1 Learning Objectives Define in general terms a stochastic process and in particular a counting process. Classify a stochastic process. Describe possible applications of mixed processes. Explain what is meant by the Markov property in the context of a stochastic process and in terms of filtrations. 8.2 Theory TO ADD THEORY ABOUT STOCHASTIC PROCESSES HERE 8.2.1 Defining stochastic process 8.2.1.1 Defining a counting process 8.2.2 Classifying stochastic processes 8.2.2.1 Time basis Continous or discrete time 8.2.2.2 State space Continous or discrete state space 8.2.2.3 Mixed type stochastic process 8.2.3 Applications of mixed processes 8.3 R Practice TO ADD R EXAMPLE ABOUT STOCHASTIC PROCESSES HERE "],
["markov-chains.html", "Chapter 9 Markov chains 9.1 Learning Objectives 9.2 Theory 9.3 R Practice", " Chapter 9 Markov chains 9.1 Learning Objectives State the essential features of a Markov chain model. State the Chapman-Kolmogorov equations that represent a Markov chain. Calculate the stationary distribution for a Markov chain in simple cases. Describe a system of frequency based experience rating in terms of a Markov chain and describe other simple applications. Describe a time-inhomogeneous Markov chain model and describe simple applications. Demonstrate how Markov chains can be used as a tool for modelling and how they can be simulated. 9.2 Theory TO ADD THEORY ABOUT MARKOV CHAINS HERE 9.2.1 Features of a Markov chain model 9.2.2 Chapman-Kolmogorov equations 9.2.3 Stationary distribution for a Markov chain 9.2.4 Frequency based experience rating 9.2.5 Time-inhomogeneous Markov chain model 9.2.6 Markov chains in modelling 9.2.6.1 Simulating a Markov chain 9.3 R Practice TO ADD R EXAMPLE ABOUT MARKOV CHAINS HERE "],
["markov-processes.html", "Chapter 10 Markov processes 10.1 Learning Objectives 10.2 Theory 10.3 R Practice", " Chapter 10 Markov processes 10.1 Learning Objectives State the essential features of a Markov process model. Define a Poisson process, derive the distribution of the number of events in a given time interval, derive the distribution of inter-event times, and apply these results. Derive the Kolmogorov equations for a Markov process with time independent and time/age dependent transition intensities. Solve the Kolmogorov equations in simple cases. State the Kolmogorov equations for a model where the transition intensities depend not only on age/time, but also on the duration of stay in one or more states. Describe sickness and marriage models in terms of duration dependent Markov processes and describe other simple applications. Demonstrate how Markov jump processes can be used as a tool for modelling and how they can be simulated. 10.2 Theory TO ADD THEORY ABOUT MARKOV PROCESSES HERE 10.2.1 Features of a Markov process model 10.2.2 Poisson process 10.2.3 Kolmogorov equations for a Markov process 10.2.4 Solving Kolmogorv equations 10.2.4.1 Simple cases 10.2.4.2 More general cases 10.2.5 Sickness and marriage models 10.2.6 Markov jump process 10.2.6.1 Simulating a Markov jump process 10.3 R Practice TO ADD R EXAMPLE ABOUT MARKOV PROCESSES HERE "],
["survival-models.html", "Chapter 11 Survival models", " Chapter 11 Survival models "],
["lifetime-distributions.html", "Chapter 12 Lifetime distributions", " Chapter 12 Lifetime distributions "],
["transition-intensities.html", "Chapter 13 Estimating transition intensities", " Chapter 13 Estimating transition intensities "],
["graduation.html", "Chapter 14 Graduation", " Chapter 14 Graduation "],
["mortality-projection.html", "Chapter 15 Mortality projection", " Chapter 15 Mortality projection "],
["machine-learning.html", "Chapter 16 Machine learning 16.1 Learning Objectives 16.2 Theory 16.3 R Practice", " Chapter 16 Machine learning 16.1 Learning Objectives Explain the main branches of machine learning and describe examples of the types of problems typically addressed by machine learning. Explain and apply high-level concepts relevant to learning from data. Describe and give examples of key supervised and unsupervised machine learning techniques, explaining the difference between regression and classification and between generative and discriminative models. Explain in detail and use appropriate software to apply machine learning techniques (e.g. penalised regression and decision trees) to simple problems. Demonstrate an understanding of the perspectives of statisticians, data scientists, and other quantitative researchers from non-actuarial backgrounds. 16.2 Theory TO ADD THEORY ABOUT MACHINE LEARNING HERE 16.2.1 Machine learning topics 16.2.2 Machine learning from data 16.2.3 Supervised machine learning 16.2.4 Unsupervised machine learning 16.2.5 Penalised regression 16.2.6 Decision trees 16.2.7 Perspectives of non-actuarial professionals 16.3 R Practice We are managing a portfolio of investments that contains 200 assets. In this portfolio we measure the following features: Price-to-Earnings Ratio (“PE”), labelled \\(x1\\) with \\(x1 \\sim \\mathcal{N}(3,\\,1)\\) Price-to-Book Ratio (“PB”), labelled \\(x2\\) with 65% of the assets following \\(\\mathcal{N}(10,\\,1)\\) and the remaining 35% following \\(\\mathcal{N}(4,\\,1)\\) We replicate this in R as follows: library(dplyr) # Data manipulation set.seed(42) # Fix result portfolio &lt;- data.frame( x1 = rnorm(200, 3, 1), x2 = scale( c( rnorm(70, 4, 1), rnorm(130, 10, 1) ) ) ) glimpse(portfolio) ## Rows: 200 ## Columns: 2 ## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.4042683, 2.8938755... ## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, -1.7225948, -1.6... Here the scale() function scales each element in the result by subtracting the sample mean and dividing by the sample standard deviation. Next we want to explore whether these 200 assets can be divided into two clusters which we will label arbitrarily A and B based on the two metrics we have measured, PE (as \\(x1\\)) and PB (as \\(x2\\)). We will first assign the assets evenly into these two clusters: group_label_stage1 &lt;- c( rep(&quot;A&quot;, 100), rep(&quot;B&quot;, 100) ) portfolio &lt;- portfolio %&gt;% mutate(group_label_stage1 = group_label_stage1) ClusterACentre &lt;- c( mean(portfolio$x1[portfolio$group_label_stage1 == &quot;A&quot;]), mean(portfolio$x2[portfolio$group_label_stage1 == &quot;A&quot;]) ) ClusterBCentre &lt;- c( mean(portfolio$x1[portfolio$group_label_stage1 == &quot;B&quot;]), mean(portfolio$x2[portfolio$group_label_stage1 == &quot;B&quot;]) ) glimpse(portfolio) ## Rows: 200 ## Columns: 3 ## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40... ## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ... ## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... We have: The centre of cluster A, given by \\((x1_A,\\, x2_A)\\) is 3.033, -0.691, and The centre of cluster B, given by \\((x1_A,\\, x2_A)\\) is 2.913, 0.691. Next we want to calculate the Euclidean distance between: \\((x1, x2)\\) and the centre of cluster A, and \\((x1, x2)\\) and the centre of cluster B. We will label these distances as dist_A and dist_B respectively. The Euclidean distance is defined as: For dist_A: \\(\\sqrt{(x1-x1_A)^2+(x2-x2_A)^2}\\), and For dist_B: \\(\\sqrt{(x1-x1_B)^2+(x2-x2_B)^2}\\). dist_A &lt;- sqrt( (portfolio$x1 - ClusterACentre[1])^2 + (portfolio$x2 - ClusterACentre[2])^2 ) dist_B &lt;- sqrt( (portfolio$x1 - ClusterBCentre[1])^2 + (portfolio$x2 - ClusterBCentre[2])^2 ) portfolio &lt;- portfolio %&gt;% mutate( dist_A = dist_A, dist_B = dist_B ) glimpse(portfolio) ## Rows: 200 ## Columns: 5 ## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40... ## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ... ## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... ## $ dist_A &lt;dbl&gt; 1.8210075, 0.7626050, 0.3871328, 0.6067517, 1.09... ## $ dist_B &lt;dbl&gt; 2.995957, 1.916835, 1.646514, 1.481271, 2.463299... Now we will update the cluster labels (A and B) by assigning to each asset the label of the cluster whose centre is nearest from dist_A and dist_B. portfolio &lt;- portfolio %&gt;% mutate( group_label_stage2 = ifelse(portfolio$dist_A &lt;= portfolio$dist_B, &quot;A&quot;, &quot;B&quot;) ) glimpse(portfolio) ## Rows: 200 ## Columns: 6 ## $ x1 &lt;dbl&gt; 4.3709584, 2.4353018, 3.3631284, 3.6328626, 3.40... ## $ x2 &lt;dbl&gt; -1.9258826, -1.1653603, -0.8925320, -0.6031994, ... ## $ group_label_stage1 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... ## $ dist_A &lt;dbl&gt; 1.8210075, 0.7626050, 0.3871328, 0.6067517, 1.09... ## $ dist_B &lt;dbl&gt; 2.995957, 1.916835, 1.646514, 1.481271, 2.463299... ## $ group_label_stage2 &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;... Let’s generate a 2x2 matrix showing the number of assets with each possible combination of values from group_label_stage1 and group_label_stage2: combos &lt;- portfolio %&gt;% count(group_label_stage1, group_label_stage2) matrix( combos$n, nrow = 2, dimnames = list( c(&quot;A&quot;, &quot;B&quot;), c(&quot;A&quot;, &quot;B&quot;) ) ) ## A B ## A 71 1 ## B 29 99 Finally let’s plot x1 and x2 coloured using the latest clustering labelling: library(ggplot2) portfolio %&gt;% ggplot() + geom_point( aes(x1, x2, colour = group_label_stage2) ) "]
]
